# Part3:APPLICATIONS OF WORLD MODELS IN AI
***
## 3.6 Interpretable and Trustworthy World Models
***
* General agents need world models [paper](https://proceedings.mlr.press/v267/richens25a.html) ![会议徽章](https://img.shields.io/badge/ICML-2025-blue)
* A Causal World Model Underlying Next Token Prediction: Exploring GPT in a Controlled Environment [paper](https://arxiv.org/abs/2412.07446) ![会议徽章](https://img.shields.io/badge/arXiv-2024.12-red)
* Transformers Use Causal World Models in Maze-Solving Tasks [paper](https://arxiv.org/abs/2412.11867) ![会议徽章](https://img.shields.io/badge/ICLR-2025-blue)
* When Do Neural Networks Learn World Models? [paper](https://arxiv.org/abs/2502.09297) ![会议徽章](https://img.shields.io/badge/arXiv-2025.02-red)
* Linear spatial world models emerge in large language models. [paper](https://arxiv.org/abs/2506.02996) ![会议徽章](https://img.shields.io/badge/arXiv-2025.06-red)
* Revisiting the othello world model hypothesis. [paper](https://arxiv.org/abs/2503.04421) ![会议徽章](https://img.shields.io/badge/arXiv-2025.03-red)
* Scaling laws for pre-training agents and world models. [paper](https://arxiv.org/abs/2411.04434) ![会议徽章](https://img.shields.io/badge/arXiv-2024.11-red)
* How hard is it to confuse a world model? [paper](https://arxiv.org/abs/2510.21232) ![会议徽章](https://img.shields.io/badge/arXiv-2025.10-red)
* Utilizing world models for adaptively covariate acquisition under limited budget for causal decision making. [paper](https://openreview.net/forum?id=wUcuUP2DjK) ![会议徽章](https://img.shields.io/badge/ICLR-2025-blue)
***
# Part4:BENCHMARK OF WORLD MODELS
***
## 4.1 Benchmark Datasets & Evaluation Metrics
***
* Frozen in time: A joint video and image encoder for end-to-end retrieval. [paper](https://arxiv.org/abs/2104.00650) ![会议徽章](https://img.shields.io/badge/ICCV-2021-blue)
* Panda-70m: Captioning 70m videos with multiple cross-modality teachers. [paper](https://arxiv.org/abs/2402.19479) ![会议徽章](https://img.shields.io/badge/CVPR-2024-blue)
* Ego4d: Around the world in 3,000 hours of egocentric video. [paper](https://arxiv.org/abs/2110.07058) ![会议徽章](https://img.shields.io/badge/CVPR-2022-blue)
* Howto100m: Learning a text-video embedding by watching hundred million narrated video clips. [paper](https://arxiv.org/abs/1906.03327) ![会议徽章](https://img.shields.io/badge/ICCV-2019-blue)
* Worldscore:A unified evaluation benchmark for world generation. [paper](https://arxiv.org/abs/2504.00983) ![会议徽章](https://img.shields.io/badge/arXiv-2025.04-red)
* Open x-embodiment: Robotic Learning Datasets and RT-X Models : Open X-Embodiment Collaboration0. [paper](https://arxiv.org/abs/2310.08864) ![会议徽章](https://img.shields.io/badge/ICRA-2024-blue)
* Room-Across-Room: Multilingual vision-and-language navigation with dense spatiotemporal grounding. [paper](https://arxiv.org/abs/2010.07954) ![会议徽章](https://img.shields.io/badge/EMNLP-2020-blue)
* Ewmbench: Evaluating scene, motion, and semantic quality in embodied world models. [paper](https://arxiv.org/abs/2505.09694) ![会议徽章](https://img.shields.io/badge/arXiv-2025.05-red)
* Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning. [paper]() ![会议徽章]()
* nuscenes: A multimodal dataset for autonomous driving. [paper]() ![会议徽章]()
* ACT-Bench: Towards Action Controllable World Models for Autonomous Driving. [paper]() ![会议徽章]()
* Jump cell painting dataset: morphological impact of 136,000 chemical and genetic perturbations. [paper]() ![会议徽章]()
* A machine learning modelto predict hepatocellular carcinoma response to transcatheter arterial chemoembolization.  [paper]() ![会议徽章]()
* The arcade learning environment: An evaluation platform for general agents. [paper]() ![会议徽章]()
* Minerl: A large-scale dataset of minecraft demonstrations. [paper]() ![会议徽章]()
* OSWorld: Benchmarking multimodal agents for open-ended tasks in real computer environments. [paper]() ![会议徽章]()
* Windows agent arena: Evaluating multi-modal OS agents at scale.  [paper]() ![会议徽章]()

