# Part3:APPLICATIONS OF WORLD MODELS IN AI
***
## 3.6 Interpretable and Trustworthy World Models
***
* General agents need world models [paper](https://proceedings.mlr.press/v267/richens25a.html) ![会议徽章](https://img.shields.io/badge/ICML-2025-blue)
* A Causal World Model Underlying Next Token Prediction: Exploring GPT in a Controlled Environment [paper](https://arxiv.org/abs/2412.07446) ![会议徽章](https://img.shields.io/badge/arXiv-2024.12-red)
* Transformers Use Causal World Models in Maze-Solving Tasks [paper]() ![会议徽章]()
* When Do Neural Networks Learn World Models? [paper]() ![会议徽章]()
* Linear spatial world models emerge in large language models. [paper]() ![会议徽章]()
* Revisiting the othello world model hypothesis. [paper]() ![会议徽章]()
* Scaling laws for pre-training agents and world models. [paper]() ![会议徽章]()
* How hard is it to confuse a world model? [paper]() ![会议徽章]()
* Utilizing world models for adaptively covariate acquisition under limited budget for causal decision making. [paper]() ![会议徽章]()
***
# Part4:BENCHMARK OF WORLD MODELS
***
## 4.1 Benchmark Datasets & Evaluation Metrics
***
* Frozen in time: A joint video and image encoder for end-to-end retrieval. [paper]() ![会议徽章]()
* Panda-70m: Captioning 70m videos with multiple cross-modality teachers. [paper]() ![会议徽章]()
* Ego4d: Around the world in 3,000 hours of egocentric video. [paper]() ![会议徽章]()
* Howto100m: Learning a text-video embedding by watching hundred million narrated video clips. [paper]() ![会议徽章]()
* Worldscore:A unified evaluation benchmark for world generation. [paper]() ![会议徽章]()
* Open x-embodiment: Robotic Learning Datasets and RT-X Models : Open X-Embodiment Collaboration0. [paper]() ![会议徽章]()
* Room-Across-Room: Multilingual vision-and-language navigation with dense spatiotemporal grounding. [paper]() ![会议徽章]()
* Ewmbench: Evaluating scene, motion, and semantic quality in embodied world models. [paper]() ![会议徽章]()
* Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning. [paper]() ![会议徽章]()
* nuscenes: A multimodal dataset for autonomous driving. [paper]() ![会议徽章]()
* ACT-Bench: Towards Action Controllable World Models for Autonomous Driving. [paper]() ![会议徽章]()
* Jump cell painting dataset: morphological impact of 136,000 chemical and genetic perturbations. [paper]() ![会议徽章]()
* A machine learning modelto predict hepatocellular carcinoma response to transcatheter arterial chemoembolization.  [paper]() ![会议徽章]()
* The arcade learning environment: An evaluation platform for general agents. [paper]() ![会议徽章]()
* Minerl: A large-scale dataset of minecraft demonstrations. [paper]() ![会议徽章]()
* OSWorld: Benchmarking multimodal agents for open-ended tasks in real computer environments. [paper]() ![会议徽章]()
* Windows agent arena: Evaluating multi-modal OS agents at scale.  [paper]() ![会议徽章]()

